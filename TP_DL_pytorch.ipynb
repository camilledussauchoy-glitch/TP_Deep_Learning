{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fdbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\Desktop\\TP5-main\\myenv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105d1f0",
   "metadata": {},
   "source": [
    "19/01/01 photo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5315a0e",
   "metadata": {},
   "source": [
    "# Manipulate the device and the precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294e638",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "In PyTorch, each tensor has a `device` and a `dtype`. The `device` refers to the device on which the tensor is currently loaded. The `dtype` is the type of data stored in the tensor. By default, `device = torch.device(\"cpu\")` and `dtype = torch.float32`.\n",
    "\n",
    "One can build a tensor directly on a given device and with a given data type (or precision) by using the optional arguments `device` and `dtype`, or we can build them first with by-default values, and send copy them on the desired device with the desired precision with the `to` method.\n",
    "\n",
    "Use both methods with devices `torch.device(\"cuda\")` and `torch.device(\"cpu\")` and with data types other than `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd1e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_cuda = torch.cuda.is_available()\n",
    "if with_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e455cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907ed42",
   "metadata": {},
   "source": [
    "# Backpropagation of the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf658d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Code libraries such as PyTorch, TensorFlow, JAX implement **automatic differentation (AutoDiff)** methods, which are at the core of ML methods trainable by gradient-based optimization techniques. These ML method include naturally neural networks.\n",
    "\n",
    "AutoDiff is based on the construction of a computational graph, which is a *Directed Acyclic Graph* (DAG). This graph represents the different stages of computation of a function $f$ at a point $\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_S)$, and we want to compute:\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\theta_1}, \\frac{\\partial f}{\\partial \\theta_2}, \\cdots,\n",
    "\\frac{\\partial f}{\\partial \\theta_S} .\n",
    "$$\n",
    "The DAG is then made of:\n",
    " * *directed* edges: represent the flows of data;\n",
    " * the root of the graph (a node which does not has any child): contains the (scalar) result of the computation of $f(\\boldsymbol{\\theta})$;\n",
    " * the leaf nodes (nodes which do not have any parent): contain the variables $(\\theta_1, \\theta_2, \\cdots, \\theta_S)$ with repect to which we want to differentiate $f$;\n",
    " * the non-leaf nodes: contain an operation to perform on their inputs.\n",
    "\n",
    "In PyTorch, the leaf nodes are built either automatically when initializing a `torch.nn.Module` (such as a linear layer, in which weights and biases are by-default leaf nodes), or manually trough the class `torch.nn.Parameter`. Tensors that we use during a computation, but that are not variables of our function are just instances of the class `torch.Tensor` (with `requires_grad = False`).\n",
    "\n",
    "The DAG is built on-the-fly during the successive operations, and the gradients are computed only when calling the `backward` method on the root node, or the function `torch.autograd.grad` on the root node and the leaf nodes with respect to which we want to differentiate. Using `backward` is very straightforward, while `torch.autograd.grad` is slightly more complex, but it supports advanced custom operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74ad5d",
   "metadata": {},
   "source": [
    "## Parameters and tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d334f",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Build some `torch.nn.Parameter`, some `torch.Tensor` and some `torch.Tensor` with `requires_grad = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e4e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093b15e6",
   "metadata": {},
   "source": [
    "Note: The main difference between a `Parameter` and a `Tensor` with `requires_grad = True` is how they are managed inside a PyTorch `Module`. To avoid any unexpected behavior, one should prefer to use `Parameter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cf550",
   "metadata": {},
   "source": [
    "## Computing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce8865",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Let $f$ be the function defined below. Compute its derivative with respect to `x1` and `x2` by using `backward`, and then by using `torch.autograd.grad`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b002c",
   "metadata": {},
   "source": [
    "### backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2837e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "c = torch.randn(3, 4, requires_grad=False)\n",
    "y = x2 * torch.sin((a * x1).sum() + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d119755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "tensor([-0.0281,  0.0284, -0.1017,  0.1672, -0.1530]) tensor(0.9717)\n"
     ]
    }
   ],
   "source": [
    "print(x1.grad, x2.grad)\n",
    "y.backward()\n",
    "print(x1.grad, x2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267787c",
   "metadata": {},
   "source": [
    "### torch.autograd.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45591c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3837, -0.1167, -0.2645,  0.0367, -0.0127])\n",
      "tensor(0.9331)\n"
     ]
    }
   ],
   "source": [
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "c = torch.randn(3, 4, requires_grad=False)\n",
    "y = x2 * torch.sin((a * x1).sum() + b)\n",
    "\n",
    "grads = torch.autograd.grad(y, (x1, x2))\n",
    "print(grads[0])\n",
    "print(grads[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37354d",
   "metadata": {},
   "source": [
    "### Higher-order derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14982627",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Compute $\\frac{\\partial f}{\\partial x_1 \\partial x_2}$ by using `torch.autograd.grad` twice. One check how to use the additional parameters `create_graph` and `allow_unused`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e036317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3012, -0.2908, -0.0313, -0.2953, -0.0058], grad_fn=<MulBackward0>) tensor(0.8676, grad_fn=<MulBackward0>)\n",
      "(tensor([-0.4182, -0.4038, -0.0435, -0.4101, -0.0081]),)\n"
     ]
    }
   ],
   "source": [
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "c = torch.randn(3, 4, requires_grad=False)\n",
    "y = x2 * torch.sin((a * x1).sum() + b)\n",
    "\n",
    "grads_x1, grads_x2 = torch.autograd.grad(y, (x1,x2), create_graph = True)\n",
    "print(grads_x1, grads_x2)\n",
    "hessian_x2_x1 = torch.autograd.grad(grads_x2, (x1,), retain_graph=True, allow_unused = True)\n",
    "print(hessian_x2_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d379e",
   "metadata": {},
   "source": [
    "## Access the computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6a896",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "The root node contains all the required information to perform the backpropagation and compute the derivatives. The graph and the nodes can be accessed with the methods `grad_fn` and `next_functions`. The leaf nodes can be accessed with the `variable` method. Before the backward, the intermediady results can be accessed with `_saved_self`.\n",
    "\n",
    "Access the various nodes of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7a1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3710, grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x0000021F66AD5C00>\n",
      "((<AccumulateGrad object at 0x0000021F66AD5E10>, 0), (<SinBackward0 object at 0x0000021F66AD67D0>, 0))\n"
     ]
    }
   ],
   "source": [
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "\n",
    "y = x2 * torch.sin((a * x1).sum() + b)\n",
    "y.backward()\n",
    "\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "print(y.grad_fn.next_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d53681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6696, grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x0000021F66AD5690>\n",
      "((<AddBackward0 object at 0x0000021F66AD7F10>, 0),)\n"
     ]
    }
   ],
   "source": [
    "# Other example\n",
    "\n",
    "x = nn.Parameter(torch.randn(6))\n",
    "y = torch.split(x, 2)\n",
    "z = sum(y).sum()\n",
    "z.backward()\n",
    "\n",
    "print(z)\n",
    "print(z.grad_fn)\n",
    "print(z.grad_fn.next_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ad993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f597f513",
   "metadata": {},
   "source": [
    "## Forward-only mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a48282",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Sometimes, for instance when testing a model, we are just interested in the result, and not the gradients. Such computations are more efficient if we are in a \"forward-only\" mode (in that situation, the computational graph is not created and the intermediary results are not stored).\n",
    "\n",
    "The easiest way is to use `with torch.no_grad()`. One can also use the method `detach` on the parameters to use their content without building the computational graph.\n",
    "\n",
    "Compute the function $f$ without building the computational graph using both methods and check that no computational graph is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb6cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4803)\n"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad()\n",
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "with torch.no_grad():\n",
    "  y = x2 * torch.sin((a * x1).sum() + b)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc72df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0142)\n"
     ]
    }
   ],
   "source": [
    "# detach() extrait contenu du résultat en oubliant tout sur le graph de calculs\n",
    "x1 = nn.Parameter(torch.randn(5)) #tensors gaussiens vecteur de taille 5-> parameter va permettre de calculer le gradient après\n",
    "x2 = nn.Parameter(torch.randn(1).squeeze()) # transforme vecteur taille 1 à un scalaire (vecteur taille 0)\n",
    "a = torch.randn(5) # crée tensors et pas paramètres\n",
    "b = torch.randn(1).squeeze()\n",
    "y = x2 * torch.sin((a * x1).sum() + b)\n",
    "with torch.no_grad():\n",
    "  y = x2.detach()* torch.sin((a * x1.detach()).sum() + b)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ea115",
   "metadata": {},
   "source": [
    "# Managing a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3c369",
   "metadata": {},
   "source": [
    "Before training a model on a dataset, we have to make some basic checks on the dataset and preprocess it correctly in order to obtain the best possible results (on a validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c2696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = \"/home/ercede23/Documents/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1010ebe",
   "metadata": {},
   "source": [
    "## Checking a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c40b1",
   "metadata": {},
   "source": [
    "First, we load MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6765b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: /home/ercede23/Documents/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting /home/ercede23/Documents/MNIST\\raw\\train-images-idx3-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 153kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/ercede23/Documents/MNIST\\raw\\train-labels-idx1-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/ercede23/Documents/MNIST\\raw\\t10k-images-idx3-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.68MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/ercede23/Documents/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to /home/ercede23/Documents/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# build transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(datasets_path, train = True,\n",
    "                              download = True, transform = transform)\n",
    "test_data = datasets.MNIST(datasets_path, train=False,\n",
    "                             download = True, transform = transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# build the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [f\"{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a34751",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "By using `numpy.random.choice`, subplots and the function `imshow` of matplotlib, print 10 (or more) random data points of the training set (image + label).\n",
    "\n",
    "Is the task feasible for a human? Do the data look clean ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3823815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcfb46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: /home/ercede23/Documents/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ff040c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.random.choice(len(train_data), 10, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
    "\n",
    "for ax, idx in zip(axes, indices):\n",
    "    img, label = train_data[idx]\n",
    "    ax.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e7db2",
   "metadata": {},
   "source": [
    "## Check for class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5abd8a",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "In classification tasks, it is common that the different classes are inequally represented in the dataset. If this \"class imbalance\" is too severe, the model is likely to fail to learn well the least represented classes.\n",
    "\n",
    "Compute the number of data points in each class (in the training dataset). What do we observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51018c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points in  0 is:  tensor(5923, dtype=torch.int32)\n",
      "number of data points in  1 is:  tensor(6742, dtype=torch.int32)\n",
      "number of data points in  2 is:  tensor(5958, dtype=torch.int32)\n",
      "number of data points in  3 is:  tensor(6131, dtype=torch.int32)\n",
      "number of data points in  4 is:  tensor(5842, dtype=torch.int32)\n",
      "number of data points in  5 is:  tensor(5421, dtype=torch.int32)\n",
      "number of data points in  6 is:  tensor(5918, dtype=torch.int32)\n",
      "number of data points in  7 is:  tensor(6265, dtype=torch.int32)\n",
      "number of data points in  8 is:  tensor(5851, dtype=torch.int32)\n",
      "number of data points in  9 is:  tensor(5949, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "counts = torch.zeros(10, dtype=torch.int)\n",
    "\n",
    "for _, label in train_data:\n",
    "  counts[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "  print('number of data points in ', i, 'is: ', counts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48180296",
   "metadata": {},
   "source": [
    "Theoretical number of data points per class if the dataset was perfectly balanced: 6000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b4129",
   "metadata": {},
   "source": [
    "# Managing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f8843e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.act_function = torch.tanh\n",
    "        layers = [1, 6, 16, 120, 84, 10]\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(layers[0], layers[1], 5, padding = 2)\n",
    "        self.conv2 = torch.nn.Conv2d(layers[1], layers[2], 5)\n",
    "        self.fc1 = torch.nn.Linear(5 * 5 * layers[2], layers[3])\n",
    "        self.fc2 = torch.nn.Linear(layers[3], layers[4])\n",
    "        self.fc3 = torch.nn.Linear(layers[4], layers[5])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act_function(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act_function(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_function(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act_function(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = torch.nn.functional.log_softmax(x, dim = 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31832bc5",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "When a `torch.nn.Module` is created, its parameters and its submodules are automatically registered, which is necessary to optimize them with an `Optimizer`. One can access them with the methods `named_parameters`, `parameters`, `named_modules`, `modules`.\n",
    "\n",
    "Access the various elements on an instance of LeNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5da91f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x0000021F66E1AB20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LeNet()\n",
    "model.parameters()\n",
    "model.named_parameters()\n",
    "model.named_modules()\n",
    "model.modules()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d014ae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0e3ae",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Create an instance of the class below and print its modules and parameters. What do we observe? Fix this issue by using the object `torch.nn.ModuleList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efe4fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SomeModel, self).__init__()\n",
    "\n",
    "        self.layers = [torch.nn.Linear(5, 5),\n",
    "                      torch.nn.ReLU(),\n",
    "                      torch.nn.Linear(5, 1)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1626f491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[('', SomeModel())]\n",
      "[SomeModel()]\n"
     ]
    }
   ],
   "source": [
    "model = SomeModel()\n",
    "\n",
    "print(list(model.named_parameters()))\n",
    "print(list(model.parameters()))\n",
    "print(list(model.named_modules()))\n",
    "print(list(model.modules()))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762febe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeModelFixed(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dadf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0219e6d4",
   "metadata": {},
   "source": [
    "**Question 3 (optional)**\n",
    "\n",
    "Check out the method `register_buffer` of `Module`, explain why it can be useful and show a use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846db9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cafae845",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8af4d",
   "metadata": {},
   "source": [
    "## Basic training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e5665",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "We want to train LeNet on MNIST. Fill the blanks in the following pieces of code.\n",
    "\n",
    "Wrap the training process into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "979745f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4013624146.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel = # ...\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = # ...\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e93a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 50\n",
    "\n",
    "#List to store loss to visualize\n",
    "valid_loss_min = np.inf # track change in validation loss\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "acc_eval = []\n",
    "#test_counter = [i*len(train_loader.dataset) for i in n_epochs]\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # ...\n",
    "\n",
    "    ######################\n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # ...\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(test_loader.dataset)\n",
    "    acc_eval.append(correct/len(test_loader.dataset)*100)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(valid_loss)\n",
    "\n",
    "    # print training/validation statistics\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869f721",
   "metadata": {},
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f35bd",
   "metadata": {},
   "source": [
    "When training a model, it is a good practice to make checkpoints every few epochs. That is, store the current state of the model **and the optimizer**. Doing so, we are able to reload the current state of a training process if:\n",
    " * the training has been interrupted for an unknown reason (which occurs when using a cluster);\n",
    " * we want to diagnose an issue with the model at an early stage (drop of performance, instabilities of the loss, etc.).\n",
    "\n",
    "It is essential to save the current state of the optimizer, since it contains frequently information acquired during the early stages of training (momentum with SGD + momentum, running means and moments with Adam).\n",
    "\n",
    "Above all, we define again a model to train and a training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48be77e",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Add lines of code to the function `train_model` to store both the model and the optimizer. One can use `torch.save` and the methods `state_dict` of `Module` and `Optimizer`. Note: one can use `torch.save` to save any PyTorch object **and** any native Python object, such as `dict`.\n",
    "\n",
    "Add options to `train_model` to resume training from a specific checkpoint.\n",
    "\n",
    "Launch a training with Adam, stop it, and then resume it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e75af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e20b7bb4",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98ef27",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "To make sure that the inputs of the neural network are within a controlled range, we usually transform the dataset to be sure that the data are centered with variance 1. It is not always necessary, but it is worth knowing it.\n",
    "\n",
    "Check the range of values on a sample of MNIST. Compute the mean and the standard deviation of the training dataset of MNIST and normalize the dataset accordingly by using `transforms.Normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6f347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "818b9fbb",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646da46f",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "It is very common to face overfitting when doing deep learning. So, several methods can be used to solve this problem. One of them is called \"data augmentation\". It consists in adding \"noise\" to data points of the training dataset in order to make the model resistant to small changes of the data.\n",
    "\n",
    "When training on images, it is common to perform \"random crops\", \"random flips\", and small \"random rotations\". With MNIST, it is meaningless to add random flips, because most digits are not supposed to be invariant by vertical or horizontal symmetries.\n",
    "\n",
    "Add random crops with `transforms.RandomCrop` with a reasonable number of pixels to the transforms to do on the dataset, visualize the resulting images and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318b642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116d6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06879324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3f62260",
   "metadata": {},
   "source": [
    "## Influence of the initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150811d",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Build a Multilayer Perceptron with ReLU activation functions, which takes 3 arguments:\n",
    " * `layers`: the list of layer sizes;\n",
    " * `sigma_w`: the standard deviation chosen for initializing the weights;\n",
    " * `with_scaling`: if True, we multiply the generated weights by $1/\\sqrt{\\# \\text{inputs}}$.\n",
    "\n",
    "Write the `reset_parameters` method, which initialize the weights according to a Gaussian distribution, either with variance $\\sigma_w^2$, or $\\sigma_w^2/\\# \\text{inputs}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, layers, sigma_w, scaling = False):\n",
    "        super(Perceptron, self).__init__()\n",
    "\n",
    "        # ...\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass\n",
    "        # ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b02ba1",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Train the model with various choices of initialization (which ones?) and try various numbers of layers with various widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f77aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20dc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a00d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e087d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826e793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d511e9a",
   "metadata": {},
   "source": [
    "**Question 5 (optional)**\n",
    "\n",
    "Implement the NTK parameterization in the `Perceptron` model: divide by $1/\\sqrt{\\# \\text{inputs}}$ the result of each layer.\n",
    "\n",
    "Train such a network with the SGD (with `scaling = False`) with learning rates of order $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bc15d",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e8888",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "Train LeNet with the SGD and Adam with default parameters and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d8cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c702031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c70eb7e",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b25e1",
   "metadata": {},
   "source": [
    "**Additional questions**\n",
    "\n",
    " * explore data augmentation with the dataset CIFAR-10\n",
    " * test different batch sizes. How to change the learning rate when we change the batch size?\n",
    " * test drop-out layers\n",
    " * read the documentation on SGD and Adam an propose a way to assign different learning rates to different sets of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324b294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe152a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdac86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
